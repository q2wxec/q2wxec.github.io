---
layout:     post
title:      "Mysql读书笔记"
subtitle:   "Mysql,架构,极客时间"
date:       2020-10-14
author:     "fxx"
header-img: "img/mysql-head.jpg"
tags:
    - Mysql
    - 丁奇专栏
    - 读书笔记
---

# MySQL 



![xmind-总结构脑图](/img/MySQL_xmind.png)

##  Server 层

### 连接器

- 1.mysql -h$ip -P$port -u$user -p
- 2.最大空闲时间wait_timeout，默认8小时
- 3.尽量使用长连接
- 4长连接导致内存占用问题

	- 1.定期断开长连接
	- 2. 5.7 或更新版本mysql_reset_connection 来重新初始化连接资源

### 查询缓存

- 1.查询缓存往往弊大于利，失效非常频繁
- 2. query_cache_type 设置成 DEMAND
- 3.MySQL 8.0删除本功能

### 分析器

- 1.词法分析，分析关键字
- 2.语法分析，判断sql语法规则

### 优化器

- 1.索引使用
- 2.表连接顺序

### 执行器

- 1.权限判断
- 2.无索引情况，遍历比较条件
- 3.有索引，根据索引查询
- 4.rows_examined扫描行数

## 存储引擎层

### InnoDB（默认）

### MyISAM

### Memory 

## 数据更新

### redo log（重做日志）

- 1. WAL 技术Write-Ahead Logging，先写日志，再写磁盘
- 2.crash-safe,已提交事务缓存中的数据为未写入磁盘
- 3. redo log 是 InnoDB 引擎特有的日志
- 4.物理日志，在某个数据页上做了什么修改
- 5.循环写
- 6.innodb_flush_log_at_trx_commit

### binlog（归档日志）

- 1. Server 层实现
- 2.逻辑日志，比如给 ID=2 这一行的 c 字段加 1 
- 3.追加写
- 4.sync_binlog 
- 5.statement - sql语句，row格式会记录行的内容

### 两阶段提交

- 1.redolog和binlog有一个共同的数据字段：XID
- 2.崩溃恢复时，会按顺序扫描redolog
如果碰到既有prepare标签又有commit标签的redolog，就直接提交
如果碰到只有prepare标签但没有commit标签的redolog，就拿着对应的XID去binlog找对应的事务
后续需要校验事务对应的binlog的完整性

### 回滚日志（undo log）

- 1.保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读
- 2.逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的

## 存储管理

### InnoDB 用缓冲池（buffer pool）管理内存

- 1.当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”
- 2. InnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进，对应的所有脏页（内存）都 flush 到磁盘上，redo log 留出空间可以继续写
- 3.刷脏页一定会写盘，就保证了每个数据页要么在磁盘要么在内存
- 4.MySQL 认为系统“空闲”的时候，只要有机会就刷一点“脏页”
- 5.MySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都 flush 到磁盘上

### 刷脏页

- LRU
- 1.一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长
- 2.日志写满，更新全部堵住，写性能跌为 0
- 3.数据库查询性能的抖动，可能是由于刷脏页导致的

### page cache

- 1.需要考虑计算机挂掉的情况
- 2.需要考虑数据分散在磁盘和缓存中协同处理的情况
- 3.page cache处于内存中，但是属于文件系统的缓存与中间件或数据库无关，从其他渠道读取文系统的数据是包括page cache中的内容

### crash-safe 保证的是

- 1.如果客户端收到事务成功的消息，事务就一定持久化了；
- 2.如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了；
- 3.如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了。

### 双 1

- sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog

### WAL 机制主要得益于两个方面

- 1.redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；
- 2.组提交机制，可以大幅度降低磁盘的 IOPS 消耗。

## 实践

### 字符串字段创建索引

- 1.直接创建完整索引，这样可能比较占用空间；
- 2.创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
- 3.倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；（身份证）
- 4.创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。

### count

- 1.基于可重复读要求，多版本并发控制，每一行记录都要判断自己是否对这个会话可见
- 2. count(*) MySQL 优化器会找到最小的那棵树来遍历
- 3.show table status 命令显示的行数也不能直接使用
- 4.解决方案，redis计数

	- 1.缓存系统可能会丢失更新
	- 2.先到 Redis 里面取出计数，再到数据表里面取数据记录，存在逻辑不一致
	- 3.这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图

- 5.计数直接放到数据库里单独的一张计数表 C,基于事务控制逻辑一致性
- 6.按照效率排序的话，count(字段)<count(主键 id)<count(1)≈count(*)，所以我建议你，尽量使用 count(*)

### orderby

- 1.全字段排序，sort_buffer，取出所有满足条件记录，快排
- 2.外部排序，sort_buffer_size不够，使用磁盘临时文件辅助，归并排
- 3.rowid 排序，单行很大，仅取id及排序字段，其他字段回表
- 4.联合索引本身有序，(city,name)，基于city条件对name排序不需要Using filesort
- 5.进一步优化，使用覆盖索引

### 获取随机消息

- 1.select word from words order by rand() limit 3;全表扫描，并通过sort_buffer排序
- 2.对于有主键的 InnoDB 表来说，rowid 就是主键 ID；
对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的
- 3.随机方案

	- 1.取得整个表的行数，并记为 C。

2.取得 Y = floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。

3.再用 limit Y,1 取得一行。
​	- 1.取得整个表的行数，记为 C；

2.根据相同的随机方法得到 Y1、Y2、Y3；

3.再执行三个 limit Y, 1 语句得到三行数据。

### 不走索引

- 1.条件字段函数操作
- 2.隐式类型转换，在 MySQL 中，字符串和数字做比较的话，是将字符串转换成数字，字段为字符串，条件为数字，则将导致不走索引，反之走，
根源还是条件字段函数操作
- 3.隐式字符编码转换，表的字符集不同，一个是 utf8，一个是 utf8mb4，所以做表连接查询的时候用不上关联字段的索引，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集

连接过程中要求在被驱动表的索引字段上加函数操作，是直接导致对被驱动表做全表扫描的原因

### 一行也慢

- 查询长时间不返回

	- 1.等 MDL 锁，sys.schema_table_lock_waits
	- 2.等 flush，show processlist 
	- 3.等行锁，sys.innodb_lock_waits 

- 执行慢

	- 所读数据在其他本事务之后开启得事务中做了多个版次得修改，由于可重复读的要求，需通过un_log获取当前事务所持有的txi的数据版本

### 临时处置

- 短连接风暴（max_connections ）

	- 1.先处理掉那些占着连接但是不工作的线程，优先断开事务外空闲太久的连接（information_schema .innodb_trx ）
	- 2.减少连接过程的消耗,让数据库跳过权限验证阶段(不建议)

- 慢查询性能问题

	- 1.索引没有设计好；
	- 2.SQL 语句没写好；

		-  insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values ("select * from t where id + 1 = ?", "select * from t where id = ? - 1", "db1");

call query_rewrite.flush_rewrite_rules();

	- 3.MySQL 选错了索引。
	
		-  force index

- QPS 突增问题

	- 1.全新业务的 bug 导致的，从数据库端直接把白名单去掉
	- 2.单独的数据库用户，用管理员账号把这个用户删掉
	- 3.查询重写功能，把压力最大的 SQL 语句直接重写成"select 1"返回。

### 读写分离

- 1.强制走主库方案；
- 2.sleep 方案；
- 3.判断主备无延迟方案（可能存在尚未发送，发送中的binglog导致延迟）；

	- 1.配合 semi-sync 方案，主库事务成功需要从库ack，binglog；
	- 2.等主库位点方案；
	- 3.等 GTID 方案。
	- 4.读延迟情况下，做更新使用乐观锁

### join查询

- Index Nested-Loop Join，驱动表全表扫，被驱动表走索引， BKA 算法优化基于数据顺序读取
- Block Nested-Loop Join（分块去 join，join_buffer_size ），驱动表，读入缓存，被驱动表逐行比对
- mysql，判断大小表为粗略数据统计，可能存在偏差，从而导致选错驱动表的情况

### group by

- 1.如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null；
- 2.尽量让 group by 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary 和 Using filesort；
- 3.如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表；
- 4.如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果

## 事务

### 隔离级别

- 读未提交
- 读已提交
- 可重复读
- 串行化

### 事务使用建议

- 1.存在对相同数据并发改的场景话，先查后改得操作需要使用行级锁select for update进行限制
- 2.set autocommit=1
- 3.SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间
- 4.监控 information_schema.Innodb_trx 表，设置长事务阈值

### 可见性

- 1.InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别
- 2.每个事务有一个唯一的事务 ID，叫作 transaction id，按申请顺序严格递增
- 3.每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id
- 4.可见性与事务版本关系

	- 1.版本未提交，不可见；
	- 2.版本已提交，但是是在视图创建后提交的，不可见；
	- 3.版本已提交，而且是在视图创建前提交的，可见。

- 5.当前读

	- 1.更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。
	- 2.除了 update 语句外，select 语句如果加锁，也是当前读。
	- 3.可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。

- 6.可重复读实现

	- 1. 事务ID并非在事务begin时就分配，而是在事务首次执行非快照读操作（SELECT ... FOR UPDATE/IN SHARE MODE、UPDATE、DELETE）时分配。
	- 2. 每个事务首次执行快照读操作时，会创建一个read_view对象（可以理解为在当前事务中，为数据表建立了一个逻辑快照，read_view对象就是用来控制此逻辑快照的可见范围的）。事务提交后，其创建的read_view对象将被销毁

		- 1. read_view->trx_ids：创建该read_view时，记录正活跃的其他事务的ID集合。事务ID在集合中降序排列，便于二分查找。
		- 2. read_view->low_limit_id：当前活跃事务中的最大事务ID+1（即系统中最近一个尚未分配出去的事务号）。
		- 3. read_view->up_limit_id：当前活跃事务中的最小事务ID。

	- 3. 如果记录的版本号比自己事务的read_view->up_limit_id小，则该记录的当前版本一定可见。因为这些版本的内容形成于快照创建之前，且它们的事务也肯定已经commit了。或者如果记录的版本号等于自己事务的事务ID，则该记录的当前版本也一定可见，因为该记录版本就是本事务产生的。
	- 4. 如果记录的版本号与自己事务的read_view->low_limit_id一样或比它更大，则该版本的记录的当前版本一定不可见。因为这些版本的内容形成于快照创建之后。
	- 5. 当无法通过4和5快速判断出记录的可见性时，则查找该记录的版本号是否在自己事务的read_view->trx_ids列表中，如果在则该记录的当前版本不可见，否则该记录的当前版本可见。
	- 6. 当一条记录判断出其当前版本不可见时，通过记录的DB_ROLL_PTR（undo段指针），尝试去当前记录的undo段中提取记录的上一个版本进行4~6中同样的可见性判断，如果可以则该记录的上一个版本可见。

## 索引

### 主键索引与非主键索引

### 索引维护，页分裂，B+树的节点分裂

### 回到主键索引树搜索的过程，我们称为回表-覆盖索引（通过联合索引实现）

### 最左前缀原则，联合索引及字符串索引（大小关系维护的原则）

### 索引下推，覆盖索引的条件判断优先处理后再回表（MySQL 5.6）

### 唯一索引和普通索引

-  change buffer 

	- 1.当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中
	- 2.change buffer 只限于用在普通索引的场景下，而不适用于唯一索引
	- 3.对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。
	- 4.redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。

### 索引统计

- 索引选择异常

	- 1.统计信息就是索引的“区分度
	- 2.采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数
	- 3.索引统计信息也不会固定不变。所以，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计
	- 4.analyze table t 命令，可以用来重新统计索引信息

- 索引选择异常处理

	- 1.采用 force index 强行选择一个索引
	- 2.考虑修改语句，引导 MySQL 使用我们期望的索引，“order by b limit 1” 改成 “order by b,a limit 1”
	- 3.可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。

## 锁

### 全局锁

- 1.Flush tables with read lock (FTWRL)全库逻辑备份
- 2.可重复读隔离级别下开启一个事务–single-transaction 

### 表级锁

- 表锁
- 元数据锁(MDL）

	- 查询会加元数据读锁，若在读锁释放前修改表结构则写锁阻塞，后续的读操作也会阻塞
	- 安全地给小表加字段

		- 解决长事务
		- 在 alter table 语句里面设定等待时间

### 行锁

- 1.行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议
- 2.如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放
- 3.死锁和死锁检测

	- 1.主动死锁检测，1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的
	- 2.临时把死锁检测关掉（不建议）
	- 3.控制并发度，对于相同行的更新，在进入引擎之前排队
	- 4.加锁访问的行上有锁，他才要检测
	- 5.死锁检测不需要扫所有事务，只扫描可能产生冲突的事务

### 间隙锁

- 1.解决幻读问题

	- 1.在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现
	- 2.幻读仅专指“新插入的行”

- 2.加在索引上
- 3.和行锁组合成next-key lock

### 加锁规则

- 1.加锁的基本单位是 next-key lock，next-key lock 是前开后闭区间。
- 2.查找过程中访问到的对象才会加锁。
- 3.索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。
- 4.索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。
- 5.一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止

## 运维

### 数据不丢 crash-safe

- 1.redo log 和 binlog 一致性保证，prepar+commit
- 2..redo log 和 binlog 完整性保证，双1，确保每次commit持久化

### 数据一致性

- 1.事务日志同步的完整过程

	- 1.在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。
	- 2.在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。
	- 3.主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。
	- 4.备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。
	- 5.sql_thread 读取中转日志，解析出日志里的命令，并执行

- 2.binlog格式statement，row，mixed，statement存在语句一致，执行不同导致主备不一致可能，row存在占用空间太大的缺陷，mixed由mysql判断，当不存在不一致风险时采用statement否则使用row
- 3.通过这条 SET TIMESTAMP 命令，MySQL 就确保了主备数据时间的一致性
- 4.双 M 结构， 在 binlog 中记录了这个命令第一次执行时所在实例的 server id，避免循环依赖

### 高可用

- 主备延迟

	- 1.主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;
	- 2.之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;
	- 3.备库 B 执行完成这个事务，我们把这个时刻记为 T3。
	- 4.所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1
	- 5. show slave status 命令，它的返回结果里面会显示 seconds_behind_master，用于表示当前备库延迟了多少秒。

- 主备延迟的来源

	- 1.备库所在机器的性能要比主库所在的机器性能差
	- 2.备库的压力大，一主多从， binlog 输出到外部系统
	- 3.大事务

- 解决主备延迟策略（主备的并行复制能力）

	- 原则

		- 1.不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中。
		- 2.同一个事务不能被拆开，必须放到同一个 worker 中。

	- 策略

		- 1.按表分发策略
		- 2.按行分发策略，5.7WRITESET
		- 3.按库并行，5.6
		- 4.按组提交并行，MariaDB 

- 主备切换

	- 可靠性优先策略

		- 1.判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步
		- 2.把主库 A 改成只读状态，即把 readonly 设置为 true；
		- 3.判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；
		- 4.把备库 B 改成可读写状态，也就是把 readonly 设置为 false；
		- 5.把业务请求切到备库 B。

	- 可用性优先策略

		- 把步骤 4、5 调整到最开始执行

### 可用性监控

- 1.select 1 只能判断库的进程还在
- 2.查表判断,我们可以检测出由于并发线程过多导致的数据库不可用的情况，无法监控空间满了
- 3.更新判断，放一个 timestamp 字段，无法判定慢
- 4.5.6 performance_schema 库

### 数据恢复

- 1.使用 delete 语句误删了数据行，可以用 Flashback 工具通过闪回把数据恢复回来，
binlog_format=row 和 binlog_row_image=FULL
预防：sql_safe_updates ，SQL 审计
- 2.误删库 / 表，全量备份，加增量日志的方式

## 复习总结

### 1.查询慢，TPS上不去解决方案

### 2.分库分表方案（ID生成，查询策略，关联策略，聚合策略，分布式事务）

### 3.主从，双主策略，数据如何保证同步，一致性

### 4.索引的数据结构，B+树的选择理由，最左优先原则的原理

### 5.异构数据源同步解决方案

### 6.MVVC一致性，原子性，持久性和日志redo-log，undo-log，bing-log关联关系及作用原理

*XMind: ZEN - Trial Version*